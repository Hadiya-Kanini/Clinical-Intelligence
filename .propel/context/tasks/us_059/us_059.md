# User Story - US_059

## Quick Reference Schema
```yaml
# User Story:
  * ID: [US_059]
  * Title: [Merge multi-document text per patient before chunking]
## Description:
   * [As a platform engineer, I want text from multiple documents merged per patient before chunking, so that context is preserved.]
## Acceptance Criteria:
   * [Given multiple documents for a patient, When processed, Then text is merged before chunking.]
## Edge Cases:
   * [What happens when documents have conflicting patient identifiers?]
## Traceability:
### Parent:
    * [EP-015]
### Tags:
    * [FR-032, AIWorker, RAG]
### Dependencies:
    * [US_058]
```
---

## Story ID
   * ID Format: US_059

## Story Title
   * Merge multi-document text per patient before chunking

## Description
  * As a platform engineer, I want text from multiple documents merged per patient before chunking, so that cross-document context is preserved for extraction.

## Acceptance Criteria
  * Given multiple documents for the same patient, When processed, Then text is merged before semantic chunking (FR-032).
  * Given document merge, When performed, Then document boundaries and source metadata are preserved.
  * Given merged text, When chunked, Then chunks can span document boundaries while maintaining source references.
  * Given patient identification, When documents are linked, Then MRN or name+DOB matching is used (FR-050).

## Edge Cases
   * What happens when documents have conflicting patient identifiers?
   * How does the system handle documents uploaded at different times?
   * What happens when the merged text is extremely large?

## Traceability
### Parent Epic
    * Epic : EP-015

### Requirement Tags
    * FR-032
    * AIWorker
    * RAG

### Dependencies
    * US_058
