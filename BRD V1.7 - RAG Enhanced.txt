Business Requirement Document: Trust-First Clinical Intelligence Platform (V1.7 - RAG Enhanced)

1. Executive Summary
This document outlines the business requirements for the Trust-First Clinical Intelligence Platform. This is a standalone, "integration-ready" application designed to address a core inefficiency in healthcare: the manual, time-consuming extraction of patient data from unstructured clinical reports.
The platform will function as a "transparent co-pilot" for all healthcare staff (including clinicians, coders, and administrators). It will ingest multiple, varied document types (e.g., Progress Notes, Continuity of Care, Clinical Notes) and use a hybrid AI engine with RAG (Retrieval-Augmented Generation) architecture to aggregate a complete, verified "360-Degree Patient View."
Unlike competitors, our platform is built on a "Trust-First" architecture. It avoids the "black box" problem by featuring Explainable AI (XAI), a RAG-powered grounding system, a Hybrid (LLM + Rules) Engine for compliance, and a critical Conflict Resolution module. This empowers users to verify a complete, accurate patient record in seconds, rather than spending 20+ minutes on manual data-gathering.

2. The Business Problem & Market Opportunity
2.1 The Core Problem
Healthcare staff are forced to spend a significant portion of their day on low-value "data-detective" work. To file a claim or prepare for a patient visit, a user must manually read dozens of pages of unstructured, multi-format PDF reports to find and re-type critical data.
This manual process is:
* Time-Consuming: It is a primary bottleneck in both clinical prep and the revenue cycle.
* Error-Prone: It leads to missed billing codes, data-entry mistakes, and a failure to identify critical data conflicts (e.g., conflicting medication lists).
* Costly: These errors directly result in claim denials (financial risk) and patient safety issues (clinical risk).
2.2 The Market Gap: Why This Is Still a Problem
A market of AI coding tools already exists, but these solutions have failed to gain universal trust and adoption. Our analysis identifies four primary market failures:
* The "Black Box" Trust Deficit: Most AI tools suggest data with no clear, verifiable evidence or explanation. Users are skeptical and must re-do the manual work, defeating the tool's purpose.
* Forced & Clunky Integration: Competitors often sell monolithic products tied to expensive, disruptive, all-or-nothing EHR integration projects. This creates a massive barrier to adoption.
* Failure to Manage Evolving Regulations: Many tools rely on static AI models that cannot keep pace with the thousands of annual billing code updates or complex, payer-specific rules.
* Singular Problem Focus: Most tools focus only on ICD coding, ignoring the user's actual job: to gather all patient data (vitals, meds, history) required for the encounter and the claim.

3. Proposed Solution: The "360-Degree Patient View"
We will build a standalone, "integration-ready" platform that acts as an intelligent data aggregator. This strategy allows us to deliver immediate value without the friction of a complex EHR integration.
The workflow is designed for trust and efficiency:
1. Ingest: A user uploads any and all reports for a patient (e.g., a Progress Note + a COC).
2. Process: Our RAG-powered Hybrid AI Engine reads, understands, and extracts all key data with document grounding.
3. Aggregate: The platform merges this data into a single, de-duplicated "360-Degree Patient View."
4. Verify: The user views the Patient 360 Dashboard with extracted data showing source metadata (document name, page number, section) and clickable reference links for critical entities (diagnoses, procedures, medications) that navigate to the specific location in the source document.
This transforms the user's job from a 20+ minute manual "search and re-type" task to a 2-minute "review and verify" action.

3.1 Asynchronous Document Processing
The platform employs a message queue system (RabbitMQ) to enable non-blocking document processing:
* User uploads are acknowledged immediately (under 5 seconds).
* Documents are queued for background processing by AI workers.
* Processing occurs asynchronously without blocking the user interface.
* Failed jobs are automatically retried (up to 3 attempts) with exponential backoff.
* Users receive real-time status updates as processing completes.
This architecture ensures scalability, fault tolerance, and optimal user experience.

3.2 Technology Stack
The platform is built on modern, enterprise-grade technologies:
* Frontend: React 19 with TypeScript, Vite, and TailwindCSS for responsive UI.
* Backend API: ASP.NET Core 8 Web API with PostgreSQL database and Entity Framework Core.
* AI Worker: Python 3.11+ with FastAPI, LangChain, Pydantic, and Google Gemini 2.5 Flash for RAG-based intelligent extraction.
* Infrastructure: RabbitMQ message broker, SMTP email service, JWT authentication.
* Document Processing: LangChain document loaders (PyPDFLoader, Docx2txtLoader), RecursiveCharacterTextSplitter for chunking.
* Document Storage: Local file system for Phase 1 (with path stored in database), cloud blob storage ready for Phase 2.
* Vector Storage: PostgreSQL with pgvector extension for semantic search and document grounding.
* AI Components:
  - LangChain (v0.1+): RAG orchestration, document loading, text splitting, embeddings, vector storage.
  - Pydantic (v2+): Data validation, entity schemas, API models.
  - Google Gemini API: Embedding (text-embedding-004) + LLM (gemini-2.5-flash).
  - pgvector (v0.2+): Vector similarity search with HNSW indexing.

3.3 RAG (Retrieval-Augmented Generation) Architecture
The platform implements RAG architecture for accurate clinical entity extraction with document grounding and explainability.

3.3.1 Vector Storage & Embeddings
* Vector Database: PostgreSQL with pgvector extension stores document chunks with 768-dimensional embeddings for semantic search.
* Embedding Model: Google Gemini Embedding API (text-embedding-004) via LangChain GoogleGenerativeAIEmbeddings wrapper.
* Document Chunking: LangChain RecursiveCharacterTextSplitter with 500-1000 token chunks, 100-token overlap, preserving document structure metadata (document_id, page, section, coordinates).

3.3.2 Clinical Entity Extraction (Core Categories)
The system prioritizes extraction of 10 core entity categories but is not limited to these. Additional relevant clinical data found in documents will also be extracted and categorized appropriately.

Patient Identification: Multiple documents are linked to the same patient via MRN (Medical Record Number) or name+DOB matching.

Core Entity Categories:
1. Patient Demographics (Name, DOB, Address, Contact, MRN)
2. Allergies (Allergen, Reaction, Severity)
3. Medications (Name, Dosage, Frequency, Route)
4. Diagnoses (Condition, Date)
5. Procedures (Procedure name, Date)
6. Lab Results (Test name, Value, Unit, Reference range)
7. Vital Signs (BP, HR, Temp, SpO2, Weight, Height)
8. Social History (Smoking, Alcohol, Occupation)
9. Clinical Notes (Provider notes, Assessment, Plan)
10. Metadata (Document type, Date, Provider, Facility)

Each extracted entity includes:
* Entity group name, entity name, entity value
* Rationale for classification
* Document location (page, section, coordinates)
* Source text citation (100% grounding requirement)

3.3.3 RAG Processing Pipeline (Optimized Single-Call)
1. Document Ingestion: Load PDF/DOCX using LangChain loaders, extract text with positional metadata.
2. Text Chunking: Split into semantic chunks (500-1000 tokens, 100-token overlap) using RecursiveCharacterTextSplitter.
3. Embedding Generation: Generate embeddings via GoogleGenerativeAIEmbeddings.
4. Vector Storage: Store chunks + embeddings in pgvector with metadata.
5. Entity Extraction Query: Generate embedding for system prompt (one-time), perform cosine similarity search, retrieve top-K relevant chunks (K=10-15).
6. Grounded Extraction: Single LLM call extracts all core entity categories plus any additional relevant clinical data with source citations. The LLM also identifies conflicts across chunks (e.g., different values for same field from different documents). Output parsed and validated using PydanticOutputParser.
7. Validation & Storage: Pydantic validates entities against schema, links to original document chunks.

Benefits: 1 embedding generation, 1 vector search, 1 LLM call (vs. 10 of each) = ~90% API cost reduction, ~80% latency reduction.

3.3.4 Document Grounding & Explainability
* Every extracted entity MUST cite source text from the document (NO hallucination).
* Provide exact location in original document (page, section, coordinates).
* Display source metadata (document name, page number, section) for all entities.
* Critical entities (diagnoses, procedures, medications) include clickable reference links to navigate to specific sections in source documents.
* Rationale provided for entity classification.

3.3.5 Vector Search Capabilities
* Semantic Search: Natural language queries over patient documents ("Find all patients with diabetes diagnosis").
* Cross-Document Search: Query across multiple uploaded documents simultaneously.
* Similarity Search: Find similar clinical cases, compare patient profiles.

4. Core Features & Differentiators
Our platform's design is based on five "Trust-First" pillars:
4.1 Multi-Document Aggregation & Conflict Resolution
The platform will ingest multiple documents, store them in a unified vector database, de-duplicate data, and, most critically, identify and surface data conflicts across all uploaded documents.

Conflict Detection Approach:
* LLM-Based Conflict Identification: The system prompt instructs the LLM to identify conflicts during entity extraction (e.g., different DOB values, conflicting allergy information, varying medication dosages across documents).
* Conflict Output Structure: Each entity group includes a "conflicts" field that lists conflicting values with their source documents.
* UI Display: Conflicts are highlighted in the Patient 360 Dashboard with side-by-side comparison of conflicting values and their sources.
* User Resolution: Users must review and select the correct value before finalizing the patient record.

This provides a direct path to reducing claim denials and patient safety risks.
4.2 Context-Aware Patient 360 Dashboard
The user interface will be designed to maximize efficiency and safety by handling data differently based on its type and criticality.
* Patient Profile Data: Extracted data (e.g., Demographics, Vitals, Medications) will be presented with source metadata (document name, page number, section) for user verification and correction.
* Actionable Billing Codes: Suggested ICD-10 and CPT codes (mapped via database lookup) will be presented with clickable reference links to source document sections. Each code includes Accept/Reject buttons for user review, with functionality to manually add codes if no match is found.
* Critical Conflicts: Data conflicts identified by the LLM (e.g., two different smoking statuses from different documents, conflicting DOB values) will be highlighted with side-by-side comparison showing source references. Users must resolve conflicts by selecting the correct value before finalization.
* Source Metadata Display: All extracted entities show document name, page number, and section name.
* Reference Links: Critical entities (diagnoses, procedures, medications) include clickable links that navigate to specific sections in source documents.
4.3 Explainable AI (XAI)
To build trust, the platform will be 100% transparent. Every extracted entity displays source metadata (document name, page number, section) to provide verifiable traceability.
* Source Metadata: All entities show document name, page number, and section name.
* Reference Links: Critical entities (diagnoses, procedures, medications) include clickable links to navigate to specific sections in source documents.
* Hover to see extraction rationale.
* RAG grounding ensures every data point cites its source (NO hallucination).
4.4 Hybrid AI Engine (RAG-Powered)
Our AI is not a single model. It is a sophisticated, multi-stage RAG system:
* Document Processing: LangChain document loaders extract text with positional metadata from PDF/DOCX files.
* Intelligent Chunking: RecursiveCharacterTextSplitter creates semantic chunks (500-1000 tokens) with overlap, preserving context across boundaries.
* Vector Retrieval: Cosine similarity search retrieves top-K most relevant chunks for entity extraction.
* LLM Core: Google Gemini 2.5 Flash with RAG context provides advanced understanding to extract all core entity categories plus additional relevant clinical data in a single call. The LLM also identifies conflicts across document chunks during extraction.
* Rule-Based Engine: ICD-10 and CPT code mapping via database lookup.
  - ICD-10 Codes: Downloaded and stored in database, searched by diagnosis text (fuzzy matching).
  - CPT Codes: Downloaded and stored in database, searched by procedure text (fuzzy matching).
  - Code Validation: Each mapped code includes Accept/Reject buttons for user review.
  - Unmapped Entities: If no matching code found, display "No ICD/CPT code found" with option to manually add.
  - Database updates: Code databases refreshed periodically to maintain current standards.
* Pydantic Validation: Type-safe entity validation against predefined schemas ensures data integrity.
4.5 Security, Compliance & Governance
* Password Management:
  - Email-based password reset with secure token links (1-hour expiration).
  - SMTP email service with TLS/SSL encryption.
  - Audit trail for all password reset activities.
* Session Management:
  - JWT-based authentication with 15-minute token expiration.
  - Automatic logout after 15 minutes of inactivity.
  - Secure logout with server-side session revocation.
* HIPAA Compliant: The platform will be 100% HIPAA-compliant across all data storage, transit, and processing. A Business Associate Agreement (BAA) will be in place.
* Role-Based Access Control (RBAC): The system strictly enforces two distinct roles: Admin (User Management, System Health) and Standard User (Patient Dashboard, Uploads). Phase 1 uses a single static admin account created during system initialization; the static admin creates all Standard User accounts.
* Immutable Audit Trail: Every single action (AI suggestion, user edit, conflict resolution) will be logged for full accountability and reporting.
* Enhanced Audit Events:
  - Authentication: LOGIN_SUCCESS, LOGIN_FAILED, LOGOUT, SESSION_EXPIRED, PASSWORD_RESET_REQUESTED, PASSWORD_RESET_COMPLETED.
  - User Management: USER_CREATED, USER_UPDATED, USER_ROLE_CHANGED, USER_DEACTIVATED, USER_REACTIVATED.
  - Document Events: DOCUMENT_UPLOADED, DOCUMENT_PROCESSING_STARTED, DOCUMENT_PROCESSING_COMPLETED, DOCUMENT_PROCESSING_FAILED.
  - Patient Data: PATIENT_360_VIEWED, PATIENT_DATA_EXPORTED, DIAGNOSIS_ADDED, DIAGNOSIS_REMOVED, MEDICATION_UPDATED, CONFLICT_RESOLVED, ICD_CODE_ACCEPTED, ICD_CODE_REJECTED, CPT_CODE_ACCEPTED, CPT_CODE_REJECTED.
  - All audit logs include: User ID, Action type, Timestamp, IP Address, and action-specific metadata.
* Rate Limiting:
  - Login attempts: 5 per minute per IP address, with account lockout after 5 failed attempts (30-minute duration).
  - Password reset: 3 attempts per hour per IP address.
  - HTTP 429 response when limits are exceeded.
* Vector Data Security:
  - Embeddings stored encrypted at rest.
  - Vector similarity search on encrypted data.
  - No PHI in embedding metadata.
  - Vector search respects user permissions with row-level security on document_chunks table.
  - Audit logging for vector queries.
  - Vector embeddings deleted with source document.
4.6 AI Clinical Assistant (RAG-Powered Chatbot)
To further reduce manual search time, the platform will include an AI-powered chat interface with RAG semantic search capabilities. Users can ask natural language questions about the ingested documents (e.g., "Summarize the patient's medication history", "Show all lab results from last visit"). The system performs vector similarity search across all patient documents and returns results ranked by relevance with source links. This allows for rapid, targeted data retrieval without re-reading the source files.
4.7 Admin Dashboard & Analytics (NEW)
To support operational oversight, the platform includes a dedicated Admin view featuring:
* User Management: Tools to create, deactivate, and manage user accounts.
* Security Logs: A searchable, granular audit trail of all system actions (e.g., ADD_DIAGNOSIS, EXPORT_DATA).
* Business Analytics: Aggregated metrics on system usage, AI accuracy trends, and processing volumes.

5. Project Scope
5.1 In-Scope (Phase 1)
* Secure user authentication with session management and automatic timeout.
* Multi-document batch upload (up to 10 files per batch: PDF and DOCX formats with comprehensive validation).
* File validation includes: extension verification (.pdf, .docx), MIME type validation, size limits (50MB max), password protection detection, corruption detection, structure integrity checks, and security scanning for suspicious content.
* Drag-and-drop interface with individual file validation and progress tracking.
* Asynchronous document processing with real-time status updates.
* Document processing status tracking: Pending, Processing, Completed, Failed, Validation_Failed.
* RAG-based document processing with vector storage and semantic search.
* Core 360-Degree Data Extraction with priority entity categories (minimum 10 core categories, extensible to additional fields as found in documents).
* ICD-10 and CPT Code Extraction with database-based mapping and Accept/Reject review functionality.
* The Patient 360 Dashboard (featuring source metadata, reference links for critical entities, conflict resolution UI, user-correction capabilities, and code review with Accept/Reject buttons).
* User Interface Pages:
  - Public: Login, Forgot Password, Reset Password.
  - Standard User: Dashboard, Document Upload, Document List, Patient 360 View (with source metadata and reference links), User Profile.
  - Admin: User Management (create, update, deactivate users).
* A "Productivity & Quality Dashboard" (User View).
* A "Admin Dashboard" (User Management, Security Logs, Business analytics with charts and graphs).
* An "API-First, Integration-Ready" architecture built on FHIR-compatible data models.
* A "Finalize & Export" function (e.g., to CSV, JSON, or clipboard).
* An AI Clinical Assistant (RAG-powered chatbot) for natural language querying with semantic search.
* Health check endpoints for system monitoring and observability.
5.2 Out-of-Scope (Phase 1)
* Direct, Bi-Directional EHR Integration: The platform will be ready for integration, but Phase 1 is a standalone product.
* Fully Autonomous (No-Human-in-the-Loop) Processing: The human user is always the final verifier. This is a core "Trust-First" principle.
* Real-time CDI Prompts at the point of care: Our tool is designed for processing completed, post-encounter reports.
* Handling non-PDF/DOCX files (e.g., .txt, direct faxes, images).

6. Key Deliverables (Platform Outputs)
The platform must successfully parse all uploaded documents and aggregate the following structured data into the "360-Degree Patient View":
* Patient Profile:
o Patient Demographics (Name, DOB, Gender, etc.)
o Document Information (Type, Visit Date)
o Allergies
o Vitals
o Social History
* Clinical Content:
o Reason for Visit
o Active Problems / Visit Diagnoses
o Medication List
o Procedures Performed
o Key Lab Results
o Plan of Treatment
* Coding Outputs:
o Suggested ICD-10 Codes (mapped via database lookup with Accept/Reject buttons)
o Suggested CPT Codes (mapped via database lookup with Accept/Reject buttons)
o Manual code entry option for unmapped diagnoses/procedures
* Core UI & Exports:
o The "Patient 360 Dashboard" (with source metadata and clickable reference links for critical entities).
o The "Productivity & Quality Dashboard" (User).
o The "Admin & Security Dashboard" (Admin).
o A finalized, exportable summary of all approved data.
o An interactive chatbot interface for natural language queries with semantic search.
* Document Processing Outputs:
o Processing status with metadata (job ID, retry count, processing time).
o Start and completion timestamps.
o File type and extraction method tracking.
o Error messages and diagnostic information for failed processing.
* RAG Processing Outputs:
o Structured entities in JSON format with core entity categories (extensible).
o Conflict identification for each entity group (conflicting values with source documents).
o Source text citations for each entity with document location metadata.
o Searchable vector database with semantic search API endpoints.
o Extraction rationale for each entity (explainability data).

7. Non-Functional Requirements (NFRs)
7.1 Security & Compliance
* HIPAA Compliance: All system components, data storage (at rest and in transit), and processing must be 100% HIPAA-compliant.
* Authentication: All application and API access must be secured via a robust authentication service.
* Audit Trail: All user actions and significant AI events must be logged in an immutable audit trail.
* Audit Detail: The system must explicitly log VIEW_PATIENT access (who viewed the PHI), in addition to edit actions.
* Automatic Session Timeout: The platform must enforce automatic logout after 15 minutes of user inactivity.
* Secure Logout: The platform must provide secure logout functionality that terminates user sessions and clears all authentication tokens.
7.2 Performance & Scalability
* Upload Acknowledgment Latency: The system must validate and acknowledge a file upload (up to 50MB) in under 5 seconds.
* Multi-Document Upload: Support batch upload of up to 10 files simultaneously with individual progress tracking.
* Maximum File Size: Single file uploads restricted to 50MB per file.
* File Type Policy: Strict "Allow List" for .pdf and .docx only with comprehensive validation including MIME type verification, password protection detection, corruption detection, structure integrity checks, and security scanning.
* Patient 360 Dashboard Load Time: Must load in under 3 seconds.
* AI Processing Time: An average 10-page PDF must be fully processed (including RAG pipeline) in under 60 seconds (asynchronous).
* Scalability: Architected to support a 100% increase in concurrent users over 6 months without degradation. Message queue enables horizontal scaling of AI workers.
* Rate Limiting:
  - Login: 5 attempts per minute per IP address.
  - Account lockout: After 5 failed login attempts for 30 minutes.
  - Password reset: 3 attempts per hour per IP address.
  - API throttling: HTTP 429 response when limits exceeded.
* RAG Performance:
  - Embedding Generation: < 2 seconds per document page.
  - Vector Search: < 500ms for similarity search (top-10 results).
  - Entity Extraction: < 15 seconds per document (10 pages) with single-call optimization.
  - Vector Database: Support 1M+ document chunks, 100K+ patient documents with HNSW indexing for sub-linear search time.
7.3 Reliability & Availability
* Availability: Targeting 99.9% uptime.
* Data Integrity: 100% data integrity guarantee.
* AI Accuracy: Target >98% AI-Human Agreement Rate.
* Entity Extraction Accuracy: > 90%.
* Grounding Accuracy: 100% (no hallucinations - every entity must have source citation).
* System Observability: Expose core metrics (queue depth, latency) to an external monitoring tool.
* Health Checks:
  - Backend API: /health endpoint for system status.
  - AI Worker: /health, /health/ready, /health/live endpoints for readiness and liveness probes.
  - Message Queue: Monitoring UI for queue metrics, message rates, and consumer status.
* Monitoring Capabilities:
  - Queue depth and processing metrics.
  - Session activity tracking.
  - Error rates and processing times.
  - Structured logging for centralized log aggregation.
* Background Services:
  - Dead letter queue monitoring for failed jobs.
* Disaster Recovery (DR): Define RPO/RTO for DB and Blob storage to ensure restoration after major incidents.
7.4 Maintainability & Usability
* Data Retention Policy: Automated policy to soft-delete/archive records after a set period (e.g., 7 years) to comply with governance standards. Vector embeddings deleted with source document.
* Rules Engine Modularity: The architecture must allow adding or modifying compliance rules (e.g., new payer logic) without requiring a full application redeployment.
* Usability: The user interface must be intuitive enough to achieve a >60% reduction in "Time-on-Task" (average time to process a patient file) as measured in User Acceptance Testing (UAT).
* Client Compatibility: The Patient 360 Dashboard must support the last two major versions of Chrome and Edge to ensure reliability across enterprise workstations.

7.5 Configuration & Deployment
* Environment Configuration:
  - Support for development, staging, and production environments.
  - Secure secret management for API keys, database credentials, and SMTP settings.
  - Environment-specific configuration files (.env) for flexible deployment.
* Backend Configuration Requirements:
  - Database connection strings (PostgreSQL with pgvector extension).
  - JWT authentication settings (secret key, token expiration).
  - Message queue connection (RabbitMQ).
  - SMTP email service configuration.
  - Rate limiting thresholds.
* AI Worker Configuration Requirements:
  - Google Gemini API key and model selection (gemini-2.5-flash, text-embedding-004).
  - Message queue connection settings.
  - File storage paths and processing limits.
  - Document chunking parameters (500-1000 tokens with 100-token overlap).
  - Vector database connection (PostgreSQL with pgvector).
  - Top-K chunks for retrieval (K=10-15).
* Deployment Architecture:
  - Standalone service deployment (no containerization required for Phase 1).
  - Message broker as Windows service for local development.
  - Batch scripts for service management and testing.
  - Health check endpoints for deployment verification.

8. High-Level Success Criteria
Success will be measured by the direct, provable value delivered to the user, as tracked by our "Productivity & Quality Dashboard."
1. Demonstrable Clinical & Financial Value:
o Metric: The "Critical Conflicts Identified" count.
o Value: This is our #1 measure of value. It is a direct, quantifiable count of prevented claim denials and patient safety risks (e.g., conflicting medication dosages across multiple documents).
2. User Productivity:
o Metric: A >60% reduction in "Time-on-Task" (average time to process a patient's complete file).
o Value: This will be measured in pilot programs via "stopwatch tests" against the manual process to prove a quantifiable return on time.
3. Platform Trust & AI Accuracy:
o Metric: An "AI-Human Agreement Rate" of >98%.
o Value: We will track the percentage of AI-suggested data that users approve without edits. This metric will be shown to increase over time as the AI fine-tunes itself, demonstrating growing trust and accuracy.
o Grounding Validation: 100% of extracted entities must have valid source citations (automated validation).
4. Widespread User Adoption:
o Metric: The "Total Patient Dashboards Created".
o Value: This tracks the sheer volume of work the platform is handling, proving it is an indispensable part of the daily workflow for clinicians and coders.

---
APPENDIX A: RAG Implementation Details

A.1 Document Processing Flow with RAG
1. User uploads document (PDF/DOCX)
2. Document queued in RabbitMQ
3. AI Worker extracts text + coordinates using LangChain loaders
4. Text chunked with overlap (500-1000 tokens) using RecursiveCharacterTextSplitter
5. Generate embeddings for each chunk via GoogleGenerativeAIEmbeddings
6. Store chunks + embeddings in pgvector with metadata (document_id, page, section)
7. Generate embedding for system prompt (one-time)
8. Perform cosine similarity search against all chunks
9. Retrieve top-K relevant chunks (K=10-15)
10. Pass system prompt + relevant chunks to Gemini (single call)
11. Gemini extracts all core entity categories plus additional relevant clinical data in one response, including conflict identification across chunks
12. Parse and validate entities using PydanticOutputParser
13. Map diagnoses to ICD-10 codes and procedures to CPT codes via database lookup (fuzzy matching)
14. Return structured entities with conflicts and mapped codes to backend
15. Display in Patient 360 View with source links, conflict resolution UI, and Accept/Reject buttons for codes

A.2 Entity Schema (Pydantic Models)
* DocumentLocation: page, section, coordinates
* ExtractedEntity: entity_group_name, entity_name, entity_value, rationale, document_location, source_text, conflicts (optional)
* Conflict: conflicting_value, source_document, document_location
* MappedCode: code_type (ICD-10/CPT), code_value, code_description, status (pending/accepted/rejected)
* PatientDemographics: name, date_of_birth, mrn, address, phone
* VitalSigns: blood_pressure, heart_rate, temperature, spo2, weight, height
* ClinicalDocument: document_id, patient_demographics, vital_signs, allergies, medications, diagnoses, procedures, lab_results, social_history, clinical_notes, metadata, created_at, additional_entities (extensible), conflicts (list)

Note: Schema is extensible to accommodate additional entity types discovered in clinical documents.

A.3 ICD-10 and CPT Code Database Schema
* Table: icd10_codes
* Columns: id, code, description, category, created_at, updated_at
* Indexes: Full-text search index on description for fuzzy matching

* Table: cpt_codes
* Columns: id, code, description, category, created_at, updated_at
* Indexes: Full-text search index on description for fuzzy matching

* Table: mapped_codes
* Columns: id, patient_id, entity_id, code_type, code_value, code_description, status, reviewed_by, reviewed_at, created_at
* Status values: pending, accepted, rejected, manually_added

A.4 Vector Database Schema
* Table: document_chunks
* Columns: id, document_id, chunk_index, page, section, content, embedding (vector), metadata (jsonb), created_at
* Indexes: HNSW index on embedding column for fast similarity search

A.5 LangChain Integration Points
* Document Loading: PyPDFLoader, Docx2txtLoader
* Text Splitting: RecursiveCharacterTextSplitter
* Embeddings: GoogleGenerativeAIEmbeddings
* Vector Store: PGVector
* Prompts: PromptTemplate
* Output Parsing: PydanticOutputParser
* LLM: GoogleGenerativeAI (gemini-2.5-flash)

---
END OF DOCUMENT
Version: 1.7 (RAG Enhanced)
Last Updated: [Current Date]
